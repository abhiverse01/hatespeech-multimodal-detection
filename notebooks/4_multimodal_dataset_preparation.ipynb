{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Modal Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>image_path</th>\n",
       "      <th>labels</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>transformed_image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nigga</td>\n",
       "      <td>dataset/images/0.jpg</td>\n",
       "      <td>[4, 1, 3]</td>\n",
       "      <td>tensor([  101,  9152, 23033,   102,     0,    ...</td>\n",
       "      <td>tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>dataset/transformed_images\\0.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my horses are retarded</td>\n",
       "      <td>dataset/images/1.jpg</td>\n",
       "      <td>[5, 5, 5]</td>\n",
       "      <td>tensor([ 101, 2026, 5194, 2024, 2128, 7559, 57...</td>\n",
       "      <td>tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>dataset/transformed_images\\1.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nigga on ma momma youngboy be spitting real sh...</td>\n",
       "      <td>dataset/images/2.jpg</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>tensor([  101,  9152, 23033,  2006,  5003, 236...</td>\n",
       "      <td>tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>dataset/transformed_images\\2.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt xxsugvngxx i ran into this holy nigga today</td>\n",
       "      <td>dataset/images/3.jpg</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>tensor([  101, 19387, 22038,  6342,  2290, 160...</td>\n",
       "      <td>tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>dataset/transformed_images\\3.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>everybody calling you nigger now</td>\n",
       "      <td>dataset/images/4.jpg</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "      <td>tensor([  101,  7955,  4214,  2017,  9152, 133...</td>\n",
       "      <td>tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>dataset/transformed_images\\4.pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text            image_path  \\\n",
       "0                                              nigga  dataset/images/0.jpg   \n",
       "1                             my horses are retarded  dataset/images/1.jpg   \n",
       "2  nigga on ma momma youngboy be spitting real sh...  dataset/images/2.jpg   \n",
       "3     rt xxsugvngxx i ran into this holy nigga today  dataset/images/3.jpg   \n",
       "4                   everybody calling you nigger now  dataset/images/4.jpg   \n",
       "\n",
       "      labels                                          input_ids  \\\n",
       "0  [4, 1, 3]  tensor([  101,  9152, 23033,   102,     0,    ...   \n",
       "1  [5, 5, 5]  tensor([ 101, 2026, 5194, 2024, 2128, 7559, 57...   \n",
       "2  [0, 0, 0]  tensor([  101,  9152, 23033,  2006,  5003, 236...   \n",
       "3  [1, 0, 0]  tensor([  101, 19387, 22038,  6342,  2290, 160...   \n",
       "4  [1, 0, 1]  tensor([  101,  7955,  4214,  2017,  9152, 133...   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1  tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,...   \n",
       "2  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "3  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "4  tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "            transformed_image_path  \n",
       "0  dataset/transformed_images\\0.pt  \n",
       "1  dataset/transformed_images\\1.pt  \n",
       "2  dataset/transformed_images\\2.pt  \n",
       "3  dataset/transformed_images\\3.pt  \n",
       "4  dataset/transformed_images\\4.pt  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = pd.read_csv(\"dataset/dataset_transformed.csv\")\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories to store tensors\n",
    "os.makedirs(\"dataset/input_ids\", exist_ok=True)\n",
    "os.makedirs(\"dataset/attention_masks\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and save tensors\n",
    "for idx in range(len(clean_data)):\n",
    "    row = clean_data.iloc[idx]\n",
    "    \n",
    "    # Tokenize text\n",
    "    inputs = tokenizer(\n",
    "        row[\"tweet_text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Remove batch dimension to get [128]\n",
    "    input_ids = inputs[\"input_ids\"].squeeze(0)\n",
    "    attention_mask = inputs[\"attention_mask\"].squeeze(0)\n",
    "    \n",
    "    # Save tensors to files\n",
    "    torch.save(inputs[\"input_ids\"], f\"dataset/input_ids/{idx}.pt\")\n",
    "    torch.save(inputs[\"attention_mask\"], f\"dataset/attention_masks/{idx}.pt\")\n",
    "    \n",
    "    # Update CSV with file paths (not tensor strings)\n",
    "    clean_data.at[idx, 'input_ids'] = f\"input_ids/{idx}.pt\"\n",
    "    clean_data.at[idx, 'attention_mask'] = f\"attention_masks/{idx}.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [0, 1, 0, 1, 1, 0]\n",
      "1    [0, 0, 0, 0, 0, 1]\n",
      "2    [1, 0, 0, 0, 0, 0]\n",
      "3    [1, 1, 0, 0, 0, 0]\n",
      "4    [1, 1, 0, 0, 0, 0]\n",
      "Name: labels, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert labels from string representation to list\n",
    "\n",
    "\n",
    "def parse_labels(label_value):\n",
    "    \"\"\"Convert worker labels into multi-hot encoding of length 6\"\"\"\n",
    "    # Convert from string to list of ints if needed\n",
    "    if isinstance(label_value, str):\n",
    "        cleaned = re.sub(r\"[^0-9]\", \" \", label_value)\n",
    "        parts = [int(x) for x in cleaned.split() if x.strip()]\n",
    "    elif isinstance(label_value, list):\n",
    "        parts = label_value\n",
    "    else:\n",
    "        parts = []\n",
    "\n",
    "    # Convert to multi-hot vector\n",
    "    multi_hot = [0] * 6\n",
    "    for label in parts:\n",
    "        if 0 <= label <= 5:\n",
    "            multi_hot[label] = 1\n",
    "    return multi_hot\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def parse_labels(label_value):\n",
    "    if isinstance(label_value, list):\n",
    "        return label_value  # Already correct format\n",
    "    # Clean strings like \"[4, 1, 3]\" or \"4 1 3\"\n",
    "    cleaned = re.sub(r\"[^0-9]\", \" \", str(label_value))\n",
    "    parts = [int(x) for x in cleaned.split() if x.strip()]\n",
    "    return (parts + [0, 0, 0])[:3]  # Ensure 3 elements\n",
    "\"\"\" \n",
    "\n",
    "clean_data[\"labels\"] = clean_data[\"labels\"].apply(parse_labels)\n",
    "print(clean_data[\"labels\"].head())\n",
    "\n",
    "# Should output:\n",
    "# 0    [4.0, 1.0, 3.0]\n",
    "# 1    [5.0, 5.0, 5.0]\n",
    "# Name: labels, dtype: object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Convert labels to string format\n",
    "for idx in range(len(clean_data)):\n",
    "    row = clean_data.iloc[idx]\n",
    "    original_labels = parse_labels(row[\"labels\"])\n",
    "    clean_data.at[idx, 'labels'] = original_labels  # Store as list [4,1,3]\n",
    "\n",
    "\n",
    "# Save updated CSV\n",
    "clean_data[\"labels\"] = clean_data[\"labels\"].apply(str)\n",
    "clean_data.to_csv(\"dataset/dataset_transformed.csv\", index=False)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Cell 6: Final CSV formatting\n",
    "clean_data.to_csv(\"dataset/dataset_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom dataset class\n",
    "clean_data[\"transformed_image_path\"] = clean_data[\"transformed_image_path\"].str.replace(\"\\\\\", \"/\")# Add this cell after loading clean_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the MultiModalDataset class\n",
    "class MultiModalDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=128):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        \n",
    "        # Load pre-saved tensors from files\n",
    "        input_ids = torch.load(os.path.join(\"dataset\", row[\"input_ids\"])).squeeze(0)\n",
    "        attention_mask = torch.load(os.path.join(\"dataset\", row[\"attention_mask\"])).squeeze(0)\n",
    "        \n",
    "        # Load image\n",
    "        image = torch.load(row[\"transformed_image_path\"])\n",
    "        \n",
    "        # Labels\n",
    "        labels = torch.tensor(row[\"labels\"], dtype=torch.float)\n",
    "        \n",
    "        return input_ids, attention_mask, image, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "dataset = MultiModalDataset(clean_data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: torch.Size([32, 128])\n",
      "Attention Mask: torch.Size([32, 128])\n",
      "Images: torch.Size([32, 3, 224, 224])\n",
      "Labels: torch.Size([32, 6])\n"
     ]
    }
   ],
   "source": [
    "# Create the DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Example: Iterate through the DataLoader\n",
    "for batch in dataloader:\n",
    "    input_ids, attention_mask, images, labels = batch\n",
    "    print(\"Input IDs:\", input_ids.shape)\n",
    "    print(\"Attention Mask:\", attention_mask.shape)\n",
    "    print(\"Images:\", images.shape)\n",
    "    print(\"Labels:\", labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [0, 1, 0, 1, 1, 0]\n",
      "1    [0, 0, 0, 0, 0, 1]\n",
      "2    [1, 0, 0, 0, 0, 0]\n",
      "3    [1, 1, 0, 0, 0, 0]\n",
      "4    [1, 1, 0, 0, 0, 0]\n",
      "Name: labels, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(pd.read_csv(\"dataset/dataset_transformed.csv\")[\"labels\"].head())\n",
    "# Should show \"[4, 1, 3]\", not raw lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        input_ids        attention_mask\n",
      "0  input_ids/0.pt  attention_masks/0.pt\n",
      "1  input_ids/1.pt  attention_masks/1.pt\n",
      "2  input_ids/2.pt  attention_masks/2.pt\n",
      "3  input_ids/3.pt  attention_masks/3.pt\n",
      "4  input_ids/4.pt  attention_masks/4.pt\n"
     ]
    }
   ],
   "source": [
    "print(pd.read_csv(\"dataset/dataset_transformed.csv\")[[\"input_ids\", \"attention_mask\"]].head())\n",
    "# Should show \"input_ids/0.pt\", not tensor strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "sample = torch.load(\"dataset/input_ids/0.pt\")\n",
    "print(sample.shape)  # Should be torch.Size([128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
