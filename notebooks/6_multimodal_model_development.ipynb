{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Modal Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries (fixed order and added missing imports)\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Verify early CUDA availability and set device\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (582017593.py, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 22\u001b[1;36m\u001b[0m\n\u001b[1;33m    def forward(self, batch):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: MultiModalModel class (fixed input handling)\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, text_encoder, image_encoder, hidden_dim=512, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.text_encoder = text_encoder\n",
    "        self.image_encoder = image_encoder\n",
    "        \n",
    "        # Freeze encoders\n",
    "        for param in self.text_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.image_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(768 + 2048, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "    \n",
    "    # Modified to accept dictionary input\n",
    "    def forward(self, batch):\n",
    "        # Text features\n",
    "        text_out = self.text_encoder(\n",
    "            input_ids=batch['input_ids'],\n",
    "            attention_mask=batch['attention_mask']\n",
    "        ).last_hidden_state[:,0,:]\n",
    "        \n",
    "        # Image features\n",
    "        img_out = self.image_encoder(batch['image']).flatten(1)\n",
    "        \n",
    "        # Combine and classify\n",
    "        combined = torch.cat((text_out, img_out), dim=1)\n",
    "        return self.classifier(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ']' does not match opening parenthesis '(' on line 15 (4237077814.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 16\u001b[1;36m\u001b[0m\n\u001b[1;33m    for col in ['input_ids', 'attention_mask', 'transformed_image_path']]):\u001b[0m\n\u001b[1;37m                                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m closing parenthesis ']' does not match opening parenthesis '(' on line 15\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Dataset Class (with path validation)\n",
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir=\"dataset\"):\n",
    "        self.data = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            row = self.data.iloc[idx]\n",
    "            \n",
    "            # Validate paths exist\n",
    "            if not all(os.path.exists(os.path.join(self.root_dir, row[col])) \n",
    "               for col in ['input_ids', 'attention_mask', 'transformed_image_path']]):\n",
    "                raise FileNotFoundError(\"Missing data files\")\n",
    "            \n",
    "            return {\n",
    "                'input_ids': torch.load(os.path.join(self.root_dir, row['input_ids'])),\n",
    "                'attention_mask': torch.load(os.path.join(self.root_dir, row['attention_mask'])),\n",
    "                'image': torch.load(os.path.join(self.root_dir, row['transformed_image_path'])),\n",
    "                'labels': torch.tensor(row['labels'], dtype=torch.float)\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping sample {idx}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Data Loading with Validation (fixed split handling)\n",
    "# Load and verify dataframe\n",
    "full_df = pd.read_csv(\"dataset/dataset_transformed.csv\")\n",
    "full_df['labels'] = full_df['labels'].apply(eval)  # Ensure labels are lists\n",
    "\n",
    "# Split data\n",
    "train_df, val_df = train_test_split(full_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = HateSpeechDataset(train_df)\n",
    "val_dataset = HateSpeechDataset(val_df)\n",
    "\n",
    "# Create dataloaders with proper collate_fn\n",
    "def collate_fn(batch):\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    return {\n",
    "        'input_ids': torch.stack([item['input_ids'] for item in batch]),\n",
    "        'attention_mask': torch.stack([item['attention_mask'] for item in batch]),\n",
    "        'image': torch.stack([item['image'] for item in batch]),\n",
    "        'labels': torch.stack([item['labels'] for item in batch])\n",
    "    }\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,  # Reduced for stability\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Model Initialization (with proper weight loading)\n",
    "text_encoder = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "image_encoder = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "image_encoder = nn.Sequential(*list(image_encoder.children())[:-1])\n",
    "\n",
    "model = MultiModalModel(text_encoder, image_encoder).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Training Setup (with gradient clipping)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading sample 3: [Errno 22] Invalid argument: 'tensor([  101, 24761,  6508,  6904, 13871,  4140,   102,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0])'\n",
      "Error loading sample 27: [Errno 22] Invalid argument: 'tensor([  101, 20907,  2057,  2746,  2005,  2017,  9152, 23033,   102,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0])'\n",
      "Error loading sample 19: [Errno 22] Invalid argument: 'tensor([  101,  2613,  4632,  7743,  2507,  1037,  6616, 10094,  2696,  9152,\\n        23033,   102,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0])'\n",
      "Error loading sample 28: [Errno 22] Invalid argument: 'tensor([  101,  8594,  2428,  2056,  6616,  8038,  3363, 10047,  1037, 22212,\\n         1998, 10047,  2182,  2000,  3828,  1996,  5304,   102,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0])'\n",
      "Error loading sample 12: [Errno 22] Invalid argument: 'tensor([  101, 14354,  2013,  2026,  5440,  1056, 24281,   102,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0])'\n",
      "Error loading sample 16: [Errno 22] Invalid argument: 'tensor([  101,  3184,  2100,  1037,  9152, 23033,  2085,  8038,  3363,  2453,\\n         3726,  2106,  7680,  2078,  2182,   102,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0])'\n",
      "Error loading sample 21: [Errno 22] Invalid argument: 'tensor([  101,  1045,  8415,  1045,  2001,  3403,  2005,  2014,  2000,  2677,\\n         1996,  2773,  9152, 13327,   102,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0])'\n",
      "Error loading sample 10: [Errno 22] Invalid argument: 'tensor([  101,  9152, 23033,  2054,   102,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0])'\n",
      "Error loading sample 18: [Errno 22] Invalid argument: 'tensor([  101, 10047,  2428,  2055,  2000,  2954,  2026,  5542,  2043,  1045,\\n         2156,  2023,  9152, 23033,   102,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0])'\n",
      "Error loading sample 31: [Errno 22] Invalid argument: 'tensor([  101,  9152, 23033,  1059,  3148,   102,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0])'\n",
      "Error loading sample 30: [Errno 22] Invalid argument: 'tensor([  101,  2061,  2017,  2735,  2000, 10474,  2005,  2009,  2612,  1997,\\n         6012,  2008,  9152, 23033,  4632,  2030,  3967,  2075,  1996,  2610,\\n         2055,  2009,   102,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0])'\n",
      "Error loading sample 35: [Errno 22] Invalid argument: 'tensor([  101,  2420,  1037, 12731,  3372,   102,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0])'\n",
      "Error loading sample 22: [Errno 22] Invalid argument: 'tensor([  101,  1996,  3256,  6949,  4744,  9152, 23033,  2001,  2066,   102,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0])'\n",
      "Error loading sample 17: [Errno 22] Invalid argument: 'tensor([  101,  3198,  1037,  9152, 23033,  2000,  2079,  2009,   102,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0])'\n",
      "Error loading sample 9: [Errno 22] Invalid argument: 'tensor([  101,  2023,  6638,  9152, 23033, 22889, 12243,  2003,  2893, 24955,\\n         2192,   102,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0])'\n",
      "Error loading sample 0: [Errno 22] Invalid argument: 'tensor([  101, 10047,  2369,  2017,  9152, 23033,  1057,  2026, 26599,  2567,\\n          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\\n            0,     0,     0,     0,     0,     0,     0,     0])'\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects a non-empty TensorList",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      7\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m      9\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Move data to device\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\100ab\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\100ab\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\100ab\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 17\u001b[0m, in \u001b[0;36mcollate_fn\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollate_fn\u001b[39m(batch):\n\u001b[0;32m     15\u001b[0m     batch \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m---> 17\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mstack([item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch]),\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mstack([item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch]),\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mstack([item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch])\n\u001b[0;32m     21\u001b[0m     }\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"
     ]
    }
   ],
   "source": [
    "# Cell 8: Training Loop (with proper validation)\n",
    "best_val_loss = float('inf')\n",
    "if __name__ == '__main__':\n",
    "    for epoch in range(5):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Move data to device\n",
    "            inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs['labels'])\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_dataloader:\n",
    "                inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "                outputs = model(inputs)\n",
    "                val_loss += criterion(outputs, inputs['labels']).item()\n",
    "        \n",
    "        # Update scheduler\n",
    "        avg_val_loss = val_loss / len(val_dataloader)\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/5\")\n",
    "        print(f\"Train Loss: {train_loss/len(train_dataloader):.4f}\")\n",
    "        print(f\"Val Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            print(\"Saved new best model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Final Model Saving (Hugging Face compatible)\n",
    "print(\"\\nTraining completed. Saving final model...\")\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "torch.save({\n",
    "    'model_state': model.state_dict(),\n",
    "    'text_config': text_encoder.config,\n",
    "    'image_config': image_encoder.state_dict()\n",
    "}, \"hate_speech_multimodal_model.pth\")\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Move model to GPU if available\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for input_ids, attention_mask, images, labels in dataloader:\n",
    "        # Move data to GPU if available\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask, images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update running loss\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Print epoch loss\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      2\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m input_ids, attention_mask, images, labels \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;66;03m# Move data to GPU if available\u001b[39;00m\n\u001b[1;32m      6\u001b[0m         input_ids \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for input_ids, attention_mask, images, labels in dataloader:\n",
    "        # Move data to GPU if available\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask, images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "# Print validation loss\n",
    "print(f\"Validation Loss: {val_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
