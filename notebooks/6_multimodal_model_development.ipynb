{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Modal Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\100ab\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import necessary libraries (fixed order and added missing imports)\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Verify early CUDA availability and set device\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Path Configuration\n",
    "PROJECT_ROOT = os.path.dirname(os.getcwd())  # Assuming notebook is in notebooks/\n",
    "DATASET_PATH = os.path.join(PROJECT_ROOT, \"notebooks/dataset\")\n",
    "EMBEDDINGS_PATH = os.path.join(PROJECT_ROOT, \"notebooks/embeddings/embeddings_0004_150samples.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multimodal Dataset Class\n",
    "import ast\n",
    "\n",
    "class MultiModalDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "        self.valid_indices = self._validate_samples()\n",
    "\n",
    "    def _validate_samples(self):\n",
    "        valid = []\n",
    "        for idx in range(len(self.data)):\n",
    "            try:\n",
    "                row = self.data.iloc[idx]\n",
    "                img_path = os.path.join(DATASET_PATH, \"transformed_images\", f\"{idx}.pt\")\n",
    "                if os.path.exists(img_path):\n",
    "                    valid.append(idx)\n",
    "            except:\n",
    "                continue\n",
    "        return valid\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_indices)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        idx = self.valid_indices[index]\n",
    "        row = self.data.iloc[idx]\n",
    "\n",
    "        input_ids_path = os.path.join(DATASET_PATH, row['input_ids'])\n",
    "        attention_mask_path = os.path.join(DATASET_PATH, row['attention_mask'])\n",
    "        image_path = os.path.join(DATASET_PATH, \"transformed_images\", f\"{idx}.pt\")\n",
    "\n",
    "        input_ids = torch.load(input_ids_path).squeeze(0)  # [1, 128] → [128]\n",
    "        attention_mask = torch.load(attention_mask_path).squeeze(0) # [1, 128] → [128]\n",
    "        # Load image tensor directly from the file\n",
    "        image = torch.load(image_path)\n",
    "        labels = torch.tensor(row['labels'], dtype=torch.float)\n",
    "        # Return labels to tensor\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'image': image,\n",
    "            'labels': labels\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Collate Function: Handles padding and batching\n",
    "def collate_fn(batch):\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    if not batch:\n",
    "        return {\n",
    "            'input_ids': torch.zeros((1, 128), dtype=torch.long),\n",
    "            'attention_mask': torch.zeros((1, 128), dtype=torch.long),\n",
    "            'image': torch.zeros((1, 3, 224, 224)),\n",
    "            'labels': torch.zeros((1, 6))\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        'input_ids': torch.stack([item['input_ids'] for item in batch]),\n",
    "        'attention_mask': torch.stack([item['attention_mask'] for item in batch]),\n",
    "        'image': torch.stack([item['image'] for item in batch]),\n",
    "        'labels': torch.stack([item['labels'] for item in batch])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Data Preparation\n",
    "df = pd.read_csv(os.path.join(DATASET_PATH, \"dataset_transformed.csv\"))\n",
    "df['labels'] = df['labels'].apply(eval)\n",
    "\n",
    "# Split data\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 samples validation:\n",
      "Sample 0: True\n",
      "Sample 1: True\n",
      "Sample 2: True\n",
      "Sample 3: True\n",
      "Sample 4: True\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Dataset Verification\n",
    "print(\"First 5 samples validation:\")\n",
    "for idx in range(5):\n",
    "    sample_path = os.path.join(DATASET_PATH, \"transformed_images\", f\"{idx}.pt\")\n",
    "    print(f\"Sample {idx}: {os.path.exists(sample_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Dataloader Initialization\n",
    "train_dataset = MultiModalDataset(train_df)\n",
    "val_dataset = MultiModalDataset(val_df)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HateSpeechClassifier Model\n",
    "\n",
    "class HateSpeechClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.text_encoder = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.img_encoder = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "        self.img_encoder = nn.Sequential(*list(self.img_encoder.children())[:-1])\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(768 + 2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 6)\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        text_features = self.text_encoder(\n",
    "            input_ids=batch['input_ids'],\n",
    "            attention_mask=batch['attention_mask']\n",
    "        ).last_hidden_state[:, 0, :]  # [CLS] token\n",
    "\n",
    "        img_features = self.img_encoder(batch['image']).squeeze(-1).squeeze(-1)  # [B, 2048, 1, 1] → [B, 2048]\n",
    "        combined = torch.cat((text_features, img_features), dim=1)  # [B, 768+2048]\n",
    "\n",
    "        return self.classifier(combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# If class is more imbalanced, we will use pos_weighted loss\\n\\n# ===== Compute pos_weight dynamically from training labels =====\\nlabel_counts = torch.zeros(6)\\nfor batch in train_loader:\\n    labels = batch[\\'labels\\']\\n    label_counts += labels.sum(dim=0)\\n\\n# Avoid division by zero\\nlabel_counts = label_counts + 1e-6  \\n\\n# Compute inverse frequency: higher weight for rarer classes\\npos_weight = (label_counts.max() / label_counts).to(device)\\n\\n# Define weighted loss function\\ncriterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\\n\\n# Optional: print weights for verification\\nprint(\"Using pos_weight for BCEWithLogitsLoss:\", pos_weight)\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 9: Training Setup\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "PATIENCE = 3\n",
    "\n",
    "model = HateSpeechClassifier().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\"\"\"\n",
    "# If class is more imbalanced, we will use pos_weighted loss\n",
    "\n",
    "# ===== Compute pos_weight dynamically from training labels =====\n",
    "label_counts = torch.zeros(6)\n",
    "for batch in train_loader:\n",
    "    labels = batch['labels']\n",
    "    label_counts += labels.sum(dim=0)\n",
    "\n",
    "# Avoid division by zero\n",
    "label_counts = label_counts + 1e-6  \n",
    "\n",
    "# Compute inverse frequency: higher weight for rarer classes\n",
    "pos_weight = (label_counts.max() / label_counts).to(device)\n",
    "\n",
    "# Define weighted loss function\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "# Optional: print weights for verification\n",
    "print(\"Using pos_weight for BCEWithLogitsLoss:\", pos_weight)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 0.6424\n",
      "Val Loss: 0.5947\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non-Hate       0.87      1.00      0.93        26\n",
      "      Racist       0.00      0.00      0.00         7\n",
      "      Sexist       0.00      0.00      0.00         5\n",
      "  Homophobic       0.00      0.00      0.00         6\n",
      "    Religion       0.00      0.00      0.00         1\n",
      "  Other Hate       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.68      0.54      0.60        48\n",
      "   macro avg       0.14      0.17      0.15        48\n",
      "weighted avg       0.47      0.54      0.50        48\n",
      " samples avg       0.73      0.64      0.64        48\n",
      "\n",
      "✅ Best model saved.\n",
      "Epoch 2/10\n",
      "Train Loss: 0.5555\n",
      "Val Loss: 0.5294\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non-Hate       0.87      1.00      0.93        26\n",
      "      Racist       0.00      0.00      0.00         7\n",
      "      Sexist       0.00      0.00      0.00         5\n",
      "  Homophobic       0.00      0.00      0.00         6\n",
      "    Religion       0.00      0.00      0.00         1\n",
      "  Other Hate       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.87      0.54      0.67        48\n",
      "   macro avg       0.14      0.17      0.15        48\n",
      "weighted avg       0.47      0.54      0.50        48\n",
      " samples avg       0.87      0.64      0.71        48\n",
      "\n",
      "✅ Best model saved.\n",
      "Epoch 3/10\n",
      "Train Loss: 0.4887\n",
      "Val Loss: 0.4866\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non-Hate       0.87      1.00      0.93        26\n",
      "      Racist       0.00      0.00      0.00         7\n",
      "      Sexist       0.00      0.00      0.00         5\n",
      "  Homophobic       0.00      0.00      0.00         6\n",
      "    Religion       0.00      0.00      0.00         1\n",
      "  Other Hate       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.87      0.54      0.67        48\n",
      "   macro avg       0.14      0.17      0.15        48\n",
      "weighted avg       0.47      0.54      0.50        48\n",
      " samples avg       0.87      0.64      0.71        48\n",
      "\n",
      "✅ Best model saved.\n",
      "Epoch 4/10\n",
      "Train Loss: 0.4364\n",
      "Val Loss: 0.4586\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non-Hate       0.87      1.00      0.93        26\n",
      "      Racist       0.00      0.00      0.00         7\n",
      "      Sexist       0.00      0.00      0.00         5\n",
      "  Homophobic       0.00      0.00      0.00         6\n",
      "    Religion       0.00      0.00      0.00         1\n",
      "  Other Hate       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.87      0.54      0.67        48\n",
      "   macro avg       0.14      0.17      0.15        48\n",
      "weighted avg       0.47      0.54      0.50        48\n",
      " samples avg       0.87      0.64      0.71        48\n",
      "\n",
      "✅ Best model saved.\n",
      "Epoch 5/10\n",
      "Train Loss: 0.4088\n",
      "Val Loss: 0.4407\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non-Hate       0.87      1.00      0.93        26\n",
      "      Racist       0.00      0.00      0.00         7\n",
      "      Sexist       0.00      0.00      0.00         5\n",
      "  Homophobic       0.00      0.00      0.00         6\n",
      "    Religion       0.00      0.00      0.00         1\n",
      "  Other Hate       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.87      0.54      0.67        48\n",
      "   macro avg       0.14      0.17      0.15        48\n",
      "weighted avg       0.47      0.54      0.50        48\n",
      " samples avg       0.87      0.64      0.71        48\n",
      "\n",
      "✅ Best model saved.\n",
      "Epoch 6/10\n",
      "Train Loss: 0.3874\n",
      "Val Loss: 0.4299\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non-Hate       0.87      1.00      0.93        26\n",
      "      Racist       0.00      0.00      0.00         7\n",
      "      Sexist       0.00      0.00      0.00         5\n",
      "  Homophobic       0.00      0.00      0.00         6\n",
      "    Religion       0.00      0.00      0.00         1\n",
      "  Other Hate       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.87      0.54      0.67        48\n",
      "   macro avg       0.14      0.17      0.15        48\n",
      "weighted avg       0.47      0.54      0.50        48\n",
      " samples avg       0.87      0.64      0.71        48\n",
      "\n",
      "✅ Best model saved.\n",
      "Epoch 7/10\n",
      "Train Loss: 0.3757\n",
      "Val Loss: 0.4243\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non-Hate       0.87      1.00      0.93        26\n",
      "      Racist       0.00      0.00      0.00         7\n",
      "      Sexist       0.00      0.00      0.00         5\n",
      "  Homophobic       0.00      0.00      0.00         6\n",
      "    Religion       0.00      0.00      0.00         1\n",
      "  Other Hate       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.87      0.54      0.67        48\n",
      "   macro avg       0.14      0.17      0.15        48\n",
      "weighted avg       0.47      0.54      0.50        48\n",
      " samples avg       0.87      0.64      0.71        48\n",
      "\n",
      "✅ Best model saved.\n",
      "Epoch 8/10\n",
      "Train Loss: 0.3583\n",
      "Val Loss: 0.4218\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non-Hate       0.87      1.00      0.93        26\n",
      "      Racist       0.00      0.00      0.00         7\n",
      "      Sexist       0.00      0.00      0.00         5\n",
      "  Homophobic       0.00      0.00      0.00         6\n",
      "    Religion       0.00      0.00      0.00         1\n",
      "  Other Hate       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.87      0.54      0.67        48\n",
      "   macro avg       0.14      0.17      0.15        48\n",
      "weighted avg       0.47      0.54      0.50        48\n",
      " samples avg       0.87      0.64      0.71        48\n",
      "\n",
      "✅ Best model saved.\n",
      "Epoch 9/10\n",
      "Train Loss: 0.3550\n",
      "Val Loss: 0.4207\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non-Hate       0.87      1.00      0.93        26\n",
      "      Racist       0.00      0.00      0.00         7\n",
      "      Sexist       0.00      0.00      0.00         5\n",
      "  Homophobic       0.00      0.00      0.00         6\n",
      "    Religion       0.00      0.00      0.00         1\n",
      "  Other Hate       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.87      0.54      0.67        48\n",
      "   macro avg       0.14      0.17      0.15        48\n",
      "weighted avg       0.47      0.54      0.50        48\n",
      " samples avg       0.87      0.64      0.71        48\n",
      "\n",
      "✅ Best model saved.\n",
      "Epoch 10/10\n",
      "Train Loss: 0.3610\n",
      "Val Loss: 0.4206\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non-Hate       0.87      1.00      0.93        26\n",
      "      Racist       0.00      0.00      0.00         7\n",
      "      Sexist       0.00      0.00      0.00         5\n",
      "  Homophobic       0.00      0.00      0.00         6\n",
      "    Religion       0.00      0.00      0.00         1\n",
      "  Other Hate       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.87      0.54      0.67        48\n",
      "   macro avg       0.14      0.17      0.15        48\n",
      "weighted avg       0.47      0.54      0.50        48\n",
      " samples avg       0.87      0.64      0.71        48\n",
      "\n",
      "✅ Best model saved.\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Training Loop\n",
    "\n",
    "# Hate Speech Labels\n",
    "LABELS = [\n",
    "    \"Non-Hate\",\n",
    "    \"Racist\",\n",
    "    \"Sexist\",\n",
    "    \"Homophobic\",\n",
    "    \"Religion\",     \n",
    "    \"Other Hate\"   \n",
    "]\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "wait = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, inputs['labels'])\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs['labels'])\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy() > 0.5\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(inputs['labels'].cpu().numpy())\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Metrics\n",
    "    preds_all = np.vstack(all_preds)\n",
    "    labels_all = np.vstack(all_labels)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(labels_all, preds_all, target_names=LABELS, zero_division=0))\n",
    "\n",
    "    # Save best model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        wait = 0\n",
    "        torch.save(model.state_dict(), os.path.join(PROJECT_ROOT, \"app/best_model_weights.pth\"))\n",
    "        print(\"✅ Best model saved.\")\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= PATIENCE:\n",
    "            print(\"⛔ Early stopping triggered.\")\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
