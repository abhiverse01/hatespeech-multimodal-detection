# Multi-Modal Hate Speech Detection using Deep Learning.

# Dataset:

- Creating a hate speech detection system using deep learning requires datasets encompassing a wide range of text, audio, and images (if applicable) to understand and detect hate speech across multiple modalities. Here are some common datasets often used for multi-modal hate speech detection:

**MMHS150K (Multi-Modal Hate Speech 150K)**:  
   - Contains 150,000 tweets, each with an associated image and labels for offensive and hate speech.
   - Focused on Twitter data, this dataset captures real-world examples of hate speech in a multi-modal format.
   - [Dataset link](https://github.com/FirojIslam/Multimodal-Hate-Speech)

This dataset is accompanied by pre-processing steps, especially for dealing with images and text separately, before feeding them into a deep learning model such as a BERT+ResNet setup for multi-modal classification tasks.
